// ============================================================================
//                                Definitions
// ============================================================================
Machine Learning
    Arthur Samuel (1959) - Field of study that gives computers the ability to learn without being explicitly programmed.
    Tom Mitchell (1998) A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.

// ============================================================================
//                                 Notation
// ============================================================================
m = Number of training examples
x = input variable / features
y = output variable / target variable
(x, y) = one training example
(x^(i), y^(i)) = ith training example
h = hypothesis function (output by the learning algorithm)
        h(x) = y

:= will represent the assignment operator, e.g., a := a+1
= will represent a truth assertion, (a = b) ? "equal" : "not equal"

// ============================================================================
//                    Linear Regression With One Variable
// ============================================================================
Also called "Univariate Linear Regression"

The squared error cost function J(theta0, theta1) is generally a good cost function to minimize

Gradient Descent Algorithm
    Used to minimize the multivariable cost function J(O1, O2) by taking repeated, simultaneous steps according to:
    O1 := O1 - alpha(d/dO1) J(O1)
    O2 := O2 - alpha(d/dO2) J(O2)

    until the values converge

    This algorithm is susceptible to falling into relative optima, but linear regression cost functions
    are convex (bowl shaped), so gradient descent will always converge to the global minimum.

    "Batch" Gradient Descent
        This references the fact that the gradient descent algorithm specified here looks at the
        entire training set and sums the error over ALL training data points, at each step

    There's a technique "normal equation method" which solves numerically for the minimum, but it doesn't
    scale as well as gradient descent

    We use linear algebra matrices and notation to handle cases where there are many more features

// ============================================================================
//                 Linear Regression With Multiple Variables
// ============================================================================
Feature Scaling:
    We need to make sure that each of our n features is on a similar scale, otherwise gradient descent may take a very long time
    to find the global minimum, because the elipses in the graph are extremely elongated

    We could scale all of the features so that they're similar--say, in [-1, 1]--then gradient descent will converge
    must faster.

    We generally don't want it to be too much bigger or smaller--as a rule of thumb, anything bigger than
    -3 to 3 or smaller than -1/3 to 1/3, then it probably needs to be scaled first.

    Mean Normalization: Can make it so that the mean has a value 0 in normalization, by applying: x(i) = (x(i) - mean) / (max value - min value)

Learning Rate:
    When alpha is chosen properly, J(theta) should be monotonically decreasing when plotted against iterations
    If it's ever increasing, use a smaller alpha

    Plot J(theta) with value on the y-axis, and number of gradient descent iterations on the x-axis

    We can also look at the plots to determine if gradient descent has converged or not. This tends to be easiest in practice, rather
    than trying to use automatic convergence threshold tests (e.g., if iter(n+1) returns a value that is smaller than iter(n) by less
    than some number epsilon

    If the learning rate seems too slow, try increasing it by ~3x (rule of thumb)

Normal Equation Method:
    This is an alternative to the gradient descent approach. Gradient descent requires choosing alpha, and needs many iterations.
    The normal equation method has neither of these drawbacks.

    However, gradient descent works well even when n (the number of features) is very large, while normal equations are very slow.
        Computing pinv(X'X) gets very expensive: invert runtime is roughly O(n^3)
        As a rule of thumb: if over 10,000 features, you'll probably have to abandon normal equations

    Note that sometimes X'X will not be invertible. Common causes of this are:
        1) Redundant features (linear dependence between features)
        2) Too many features (m <= n)
            This can be solved with a technique called regularization

// ============================================================================
//                               Vectorization
// ============================================================================
Implementingthings as vector multiplication instead of for-loops can be
vastly faster
